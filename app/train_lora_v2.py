"""
LoRA è¨“ç·´è…³æœ¬ v2
ä½¿ç”¨çµ±ä¸€é…ç½®ç³»çµ±
"""

import argparse
import logging
from datetime import datetime
from pathlib import Path

import evaluate
import numpy as np
import psutil
import torch
import yaml
from datasets import load_dataset
from peft import LoraConfig, get_peft_model
from transformers import (
    AutoModelForSequenceClassification,
    AutoTokenizer,
    Trainer,
    TrainerCallback,
    TrainingArguments,
)

from app.config import load_config
from app.data_management import (
    DataValidator,
    DataVersionManager,
    analyze_distribution,
    get_data_summary,
)
from app.db import Database, ExperimentRecord
from app.logger_config import setup_progress_logger, setup_system_logger
from app.monitoring import PerformanceMonitor
from app.tools.checkpoint_manager import CheckpointManager

# å…¨å±€ loggerï¼Œæœƒåœ¨ setup_experiment_dir ä¸­åˆå§‹åŒ–
logger: logging.Logger


class TrainingProgressCallback(TrainerCallback):
    """è¨“ç·´é€²åº¦è¨˜éŒ„ callback"""

    def __init__(self, log_file):
        super().__init__()
        self.logger = setup_progress_logger(log_file)

    def on_log(self, args, state, control, logs=None, **kwargs):
        """è¨˜éŒ„è¨“ç·´é€²åº¦"""
        if logs:
            metrics = []
            for key in ["loss", "learning_rate", "epoch", "eval_loss", "eval_accuracy"]:
                if key in logs:
                    value = logs[key]
                    metrics.append(f"{key}={value:.4f}")

            if metrics:
                message = f"Step {state.global_step}: {' | '.join(metrics)}"
                self.logger.info(message)

    def on_evaluate(self, args, state, control, metrics=None, **kwargs):
        """è¨˜éŒ„è©•ä¼°çµæœ"""
        if metrics:
            eval_metrics = []
            for key, value in metrics.items():
                if isinstance(value, (int, float)):
                    eval_metrics.append(f"{key}={value:.4f}")
                else:
                    eval_metrics.append(f"{key}={value}")

            if eval_metrics:
                message = f"Evaluation: {' | '.join(eval_metrics)}"
                self.logger.info(message)


def setup_device(config):
    """è¨­ç½®è¨“ç·´è¨­å‚™"""
    if config.training.device:
        return torch.device(config.training.device)

    if torch.cuda.is_available():
        device = torch.device("cuda")
        logger.info("ğŸš€ ä½¿ç”¨ CUDA GPU åŠ é€Ÿ")
    elif torch.backends.mps.is_available():
        device = torch.device("mps")
        logger.info("ğŸš€ ä½¿ç”¨ MPS åŠ é€Ÿï¼ˆApple Siliconï¼‰")
    else:
        device = torch.device("cpu")
        logger.info("âš ï¸ æœªæª¢æ¸¬åˆ° GPUï¼Œä½¿ç”¨ CPU æ¨¡å¼")

    return device


def load_model_and_tokenizer(config, device):
    """è¼‰å…¥æ¨¡å‹èˆ‡ tokenizer"""
    logger.info("ğŸ“¥ è¼‰å…¥æ¨¡å‹èˆ‡ tokenizer...")
    tokenizer = AutoTokenizer.from_pretrained(config.model.name)
    model = AutoModelForSequenceClassification.from_pretrained(
        config.model.name, num_labels=config.model.num_labels
    ).to(device)
    logger.info(f"âœ… æ¨¡å‹è¼‰å…¥å®Œæˆ: {config.model.name}")
    return model, tokenizer


def load_and_process_data(config, tokenizer):
    """è¼‰å…¥èˆ‡è™•ç†è³‡æ–™"""
    logger.info("ğŸ“Š è¼‰å…¥è³‡æ–™é›†...")
    try:
        dataset = load_dataset(config.data.dataset_name, config.data.dataset_config)
    except Exception as e:
        raise ValueError(f"ç„¡æ³•è¼‰å…¥æ•¸æ“šé›† {config.data.dataset_name}: {str(e)}")

    # æª¢æŸ¥æ•¸æ“šé›†æ˜¯å¦å­˜åœ¨å¿…è¦çš„åˆ†å‰²
    required_splits = ["train", "validation"]
    for split in required_splits:
        if split not in dataset:
            raise ValueError(f"æ•¸æ“šé›†ç¼ºå°‘å¿…è¦çš„åˆ†å‰²: {split}")

    # é¸æ“‡æŒ‡å®šæ•¸é‡çš„æ¨£æœ¬
    try:
        train_small = dataset["train"].select(range(config.data.train_samples))
        eval_small = dataset["validation"].select(range(config.data.eval_samples))
    except Exception as e:
        raise ValueError(f"é¸æ“‡æ•¸æ“šæ¨£æœ¬æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")

    # æª¢æŸ¥æ•¸æ“šé›†å¤§å°
    if len(train_small) == 0:
        raise ValueError("è¨“ç·´æ•¸æ“šé›†ä¸èƒ½ç‚ºç©º")
    if len(eval_small) == 0:
        raise ValueError("é©—è­‰æ•¸æ“šé›†ä¸èƒ½ç‚ºç©º")

    logger.info(f"   - è¨“ç·´è³‡æ–™: {len(train_small)} ç­†")
    logger.info(f"   - é©—è­‰è³‡æ–™: {len(eval_small)} ç­†")

    # è³‡æ–™åˆ†æ
    logger.info("ğŸ“‹ é€²è¡Œè³‡æ–™åˆ†æèˆ‡ç®¡ç†...")
    summary = get_data_summary(train_small)
    logger.info("ğŸ“Š è³‡æ–™æ‘˜è¦:")
    logger.info(f"   - ç‰¹å¾µæ•¸: {summary['num_features']}")
    logger.info(f"   - ç‰¹å¾µåç¨±: {summary['feature_names']}")

    distribution_analysis = analyze_distribution(train_small)
    logger.info("ğŸ“Š é¡åˆ¥åˆ†å¸ƒ:")
    logger.info(f"   - é¡åˆ¥æ•¸: {distribution_analysis['num_classes']}")
    logger.info(f"   - å„é¡åˆ¥æ•¸é‡: {distribution_analysis['label_counts']}")
    logger.info(f"   - ä¸å¹³è¡¡æ¯”ä¾‹: {distribution_analysis['imbalance_ratio']:.2f}:1")
    logger.info(
        f"   - æ˜¯å¦å¹³è¡¡: {'âœ…' if distribution_analysis['is_balanced'] else 'âŒ'}"
    )

    # è³‡æ–™é©—è­‰
    validator = DataValidator(logger)
    validator.set_validation_rules(config.data.validation_rules)
    validation_report = validator.validate_dataset(train_small, ["sentence"])
    total_issues = sum(
        len(issue_list) for issue_list in validation_report["issues"].values()
    )

    if total_issues > 0:
        logger.warning(f"âš ï¸ ç™¼ç¾ {total_issues} å€‹è³‡æ–™å•é¡Œ")
        train_small = validator.clean_dataset(
            train_small, ["sentence"], validation_report
        )
        logger.info(f"ğŸ§¹ è³‡æ–™æ¸…ç†å®Œæˆï¼Œå‰©é¤˜ {len(train_small)} ç­†è¨“ç·´è³‡æ–™")
    else:
        logger.info("âœ… è³‡æ–™é©—è­‰é€šéï¼Œç„¡å•é¡Œç™¼ç¾")

    # ç‰ˆæœ¬ç®¡ç†
    try:
        version_manager = DataVersionManager(logger=logger)
        current_version = version_manager.get_current_version()
        if current_version:
            logger.info(f"ğŸ“¦ ç•¶å‰è³‡æ–™ç‰ˆæœ¬: {current_version}")
        else:
            version_name = f"sst2_train_{len(train_small)}samples"
            version_manager.create_version(
                train_small,
                version_name,
                description=f"SST-2 è¨“ç·´é›†ï¼Œç¶“éæ¸…ç†ï¼Œ{len(train_small)} ç­†è³‡æ–™",
                cleaning_strategy="ç§»é™¤ç©ºå€¼ã€HTMLæ¨™ç±¤æ¸…ç†ã€é‡è¤‡è³‡æ–™ç§»é™¤",
                source_info={
                    "dataset": f"{config.data.dataset_name}/{config.data.dataset_config}",
                    "split": "train",
                    "original_samples": config.data.train_samples,
                    "cleaned_samples": len(train_small),
                },
            )
            logger.info(f"ğŸ“¦ å‰µå»ºè³‡æ–™ç‰ˆæœ¬: {version_name}")
    except Exception as e:
        logger.warning(f"âš ï¸ ç‰ˆæœ¬ç®¡ç†å¤±æ•—: {e}")

    logger.info("=" * 50)

    # è³‡æ–™è™•ç†
    def tokenize(batch):
        # è¨ˆç®— token é•·åº¦
        token_lengths = [len(tokenizer.encode(text)) for text in batch["sentence"]]
        max_token_length = max(token_lengths)

        # å¦‚æœæœ‰è¶…é•·åºåˆ—ï¼Œè¨˜éŒ„è­¦å‘Š
        if max_token_length > config.data.max_length:
            num_truncated = sum(
                1 for length in token_lengths if length > config.data.max_length
            )
            logger.warning(
                f"ç™¼ç¾ {num_truncated} å€‹è¶…é•·åºåˆ— "
                f"(æœ€é•·: {max_token_length} tokens, "
                f"é™åˆ¶: {config.data.max_length} tokens)"
            )

        # åŸ·è¡Œ tokenize
        return tokenizer(
            batch["sentence"],
            padding="max_length",
            truncation=True,
            max_length=config.data.max_length,
            # ä¸è¿”å› overflowing_tokensï¼Œå› ç‚ºå®ƒæœƒæ”¹è®Šåºåˆ—é•·åº¦
            return_length=True,  # è¿”å›åºåˆ—é•·åº¦ä¿¡æ¯
        )

    train_dataset = train_small.map(tokenize, batched=True)
    eval_dataset = eval_small.map(tokenize, batched=True)
    logger.info("âœ… è¨“ç·´å’Œé©—è­‰è³‡æ–™é›†è™•ç†å®Œæˆ")

    return train_dataset, eval_dataset


def setup_lora(config, model, device):
    """è¨­ç½® LoRA"""
    lora_config = LoraConfig(
        r=config.lora.r,
        lora_alpha=config.lora.lora_alpha,
        target_modules=config.lora.target_modules,
        lora_dropout=config.lora.lora_dropout,
        bias=config.lora.bias,
        task_type=config.lora.task_type,
    )
    model = get_peft_model(model, lora_config).to(device)
    logger.info("âœ… LoRA é…ç½®å®Œæˆ")

    # é¡¯ç¤ºå¯è¨“ç·´åƒæ•¸æ•¸é‡
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    total_params = sum(p.numel() for p in model.parameters())
    logger.info(
        f"ğŸ“Š å¯è¨“ç·´åƒæ•¸: {trainable_params:,} / {total_params:,} ({trainable_params / total_params * 100:.2f}%)"
    )

    return model


def setup_training(config, model, train_dataset, eval_dataset, exp_dir):
    """è¨­ç½®è¨“ç·´"""
    # è©•ä¼°æ–¹æ³•
    logger.info("ğŸ“ˆ è¨­ç½®è©•ä¼°æ–¹æ³•...")
    metric = evaluate.load("accuracy")

    def compute_metrics(eval_pred):
        logits, labels = eval_pred
        preds = np.argmax(logits, axis=-1)
        return metric.compute(predictions=preds, references=labels)

    # è¨“ç·´åƒæ•¸
    logger.info("âš™ï¸ è¨­ç½®è¨“ç·´åƒæ•¸...")
    training_args = TrainingArguments(
        output_dir=config.training.output_dir,
        learning_rate=config.training.learning_rate,
        per_device_train_batch_size=config.training.per_device_train_batch_size,
        num_train_epochs=config.training.num_train_epochs,
        logging_steps=config.training.logging_steps,
        report_to=None,
        # Checkpoint ç›¸é—œé…ç½®
        save_strategy="epoch",  # æ¯å€‹ epoch ä¿å­˜ä¸€æ¬¡
        save_total_limit=None,  # ä¸é™åˆ¶ä¿å­˜æ•¸é‡ï¼Œç”± CheckpointManager ç®¡ç†
        eval_strategy="epoch",  # æ¯å€‹ epoch è©•ä¼°ä¸€æ¬¡
        load_best_model_at_end=True,  # è¨“ç·´çµæŸå¾Œè¼‰å…¥æœ€ä½³æ¨¡å‹
        metric_for_best_model="eval_accuracy",  # ä½¿ç”¨é©—è­‰æº–ç¢ºç‡é¸æ“‡æœ€ä½³æ¨¡å‹
        greater_is_better=True,  # æŒ‡æ¨™è¶Šå¤§è¶Šå¥½
    )

    logger.info("ğŸ“ è¨“ç·´åƒæ•¸:")
    logger.info(f"   - å­¸ç¿’ç‡: {training_args.learning_rate}")
    logger.info(f"   - æ‰¹æ¬¡å¤§å°: {training_args.per_device_train_batch_size}")
    logger.info(f"   - è¨“ç·´è¼ªæ•¸: {training_args.num_train_epochs}")
    logger.info(f"   - è¨˜éŒ„é »ç‡: æ¯ {training_args.logging_steps} æ­¥")

    logger.info("ğŸ“ Checkpoint è¨­ç½®:")
    logger.info("   - ä¿å­˜ç­–ç•¥: æ¯å€‹ epoch")
    logger.info("   - è©•ä¼°ç­–ç•¥: æ¯å€‹ epoch")
    logger.info(f"   - è¼‰å…¥æœ€ä½³æ¨¡å‹: {training_args.load_best_model_at_end}")
    logger.info(f"   - è©•ä¼°æŒ‡æ¨™: {training_args.metric_for_best_model}")
    logger.info("   - ä¿ç•™ä¸‰å€‹é—œéµ checkpoints:")
    logger.info("     1. æœ€ä½³è©•ä¼°æº–ç¢ºç‡")
    logger.info("     2. æœ€å¾Œä¸€å€‹ï¼ˆç”¨æ–¼æ¢å¾©è¨“ç·´ï¼‰")
    logger.info("     3. è¨“ç·´æ™‚é–“æœ€çŸ­ï¼ˆç”¨æ–¼å¿«é€Ÿå¯¦é©—ï¼‰")

    # å‰µå»ºè‡ªå®šç¾© callbackï¼Œä½¿ç”¨å¯¦é©—ç›®éŒ„ä¸­çš„æ—¥èªŒæ–‡ä»¶
    progress_callback = TrainingProgressCallback(exp_dir / "logs.txt")

    # å‰µå»º Trainer
    trainer = Trainer(
        model=model,
        args=training_args,
        train_dataset=train_dataset,
        eval_dataset=eval_dataset,
        compute_metrics=compute_metrics,
        callbacks=[progress_callback],
    )

    return trainer


def train_and_evaluate(config, trainer):
    """è¨“ç·´èˆ‡è©•ä¼°"""
    logger.info("ğŸš€ é–‹å§‹è¨“ç·´...")
    logger.info("=" * 50)

    # æª¢æŸ¥åˆå§‹è¨˜æ†¶é«”ç‹€æ…‹
    if torch.cuda.is_available():
        torch.cuda.reset_peak_memory_stats()
        initial_gpu_memory = torch.cuda.memory_allocated() / 1024**3  # GB
        logger.info(f"åˆå§‹ GPU è¨˜æ†¶é«”ä½¿ç”¨: {initial_gpu_memory:.2f}GB")

    # è¨“ç·´
    try:
        train_result = trainer.train()
        logger.info("ğŸ‰ è¨“ç·´å®Œæˆï¼")

        # è¨˜éŒ„æœ€å¤§è¨˜æ†¶é«”ä½¿ç”¨é‡
        if torch.cuda.is_available():
            peak_gpu_memory = torch.cuda.max_memory_allocated() / 1024**3  # GB
            current_gpu_memory = torch.cuda.memory_allocated() / 1024**3  # GB
            logger.info(f"æœ€å¤§ GPU è¨˜æ†¶é«”ä½¿ç”¨: {peak_gpu_memory:.2f}GB")
            logger.info(f"ç•¶å‰ GPU è¨˜æ†¶é«”ä½¿ç”¨: {current_gpu_memory:.2f}GB")

            # æª¢æŸ¥æ˜¯å¦æ¥è¿‘è¨˜æ†¶é«”é™åˆ¶
            total_gpu_memory = (
                torch.cuda.get_device_properties(0).total_memory / 1024**3
            )
            if peak_gpu_memory > total_gpu_memory * 0.9:  # ä½¿ç”¨è¶…é 90% çš„è¨˜æ†¶é«”
                logger.warning(
                    f"âš ï¸ GPU è¨˜æ†¶é«”ä½¿ç”¨ç‡éé«˜: {(peak_gpu_memory / total_gpu_memory) * 100:.1f}%"
                )
    except RuntimeError as e:
        if "out of memory" in str(e):
            if torch.cuda.is_available():
                current_gpu_memory = torch.cuda.memory_allocated() / 1024**3
                total_gpu_memory = (
                    torch.cuda.get_device_properties(0).total_memory / 1024**3
                )
                raise RuntimeError(
                    f"GPU è¨˜æ†¶é«”ä¸è¶³: å·²ä½¿ç”¨ {current_gpu_memory:.1f}GB / ç¸½è¨ˆ {total_gpu_memory:.1f}GB"
                ) from e
            else:
                current_memory = psutil.Process().memory_info().rss / 1024**3
                total_memory = psutil.virtual_memory().total / 1024**3
                raise RuntimeError(
                    f"CPU è¨˜æ†¶é«”ä¸è¶³: å·²ä½¿ç”¨ {current_memory:.1f}GB / ç¸½è¨ˆ {total_memory:.1f}GB"
                ) from e
        raise

    logger.info("=" * 50)

    # è©•ä¼°
    logger.info("ğŸ“Š è©•ä¼°æ¨¡å‹...")
    eval_result = trainer.evaluate()
    logger.info(f"âœ… é©—è­‰æº–ç¢ºç‡: {eval_result['eval_accuracy']:.4f}")

    # ä¿å­˜æ¨¡å‹
    output_dir = Path(config.training.output_dir) / "final_model"
    logger.info(f"ğŸ’¾ ä¿å­˜æ¨¡å‹åˆ° {output_dir}...")
    trainer.save_model(str(output_dir))
    logger.info("âœ… æ¨¡å‹ä¿å­˜å®Œæˆ")

    # è¨“ç·´ç¸½çµ
    logger.info("ğŸ¯ è¨“ç·´ç¸½çµ:")
    logger.info(f"   - ç¸½è¨“ç·´æ­¥æ•¸: {train_result.global_step}")
    logger.info(f"   - ç¸½è¨“ç·´æ™‚é–“: {train_result.metrics['train_runtime']:.2f} ç§’")
    logger.info(f"   - é©—è­‰æº–ç¢ºç‡: {eval_result['eval_accuracy']:.4f}")
    logger.info(f"   - æ¨¡å‹ä¿å­˜ä½ç½®: {output_dir}")

    return train_result, eval_result


def save_experiment_results(exp_dir, config, train_result, eval_result, trainer):
    """ä¿å­˜å¯¦é©—çµæœä¸¦ç®¡ç† checkpoints"""
    # æ¸…ç†ç•¶å‰å¯¦é©—çš„ checkpoints
    artifacts_dir = exp_dir / "artifacts"
    checkpoint_manager = CheckpointManager(results_dir=str(artifacts_dir))
    checkpoint_manager.cleanup_experiment(artifacts_dir)

    # å‰µå»ºæ•ˆèƒ½ç›£æ§å™¨
    monitor = PerformanceMonitor(exp_dir)

    # æ›´æ–°åºåˆ—é•·åº¦çµ±è¨ˆ
    for batch in trainer.get_train_dataloader():
        monitor.update_sequence_length(
            len(batch["input_ids"]), batch["input_ids"].shape[1]
        )

    # ä¿å­˜å®Œæ•´æŒ‡æ¨™
    metrics = monitor.save_metrics(trainer, train_result, eval_result)

    # ä¿å­˜é…ç½®
    config_dict = config.model_dump()  # ä½¿ç”¨ model_dump æ›¿ä»£ dict
    config_dict["results"] = metrics
    config_file = exp_dir / "config.yaml"
    with open(config_file, "w", encoding="utf-8") as f:
        yaml.dump(config_dict, f, allow_unicode=True, sort_keys=False)

    # ä¿å­˜åˆ°è³‡æ–™åº«
    db = Database()
    db.save_experiment(
        ExperimentRecord(
            id=exp_dir.name,  # ä½¿ç”¨å¯¦é©—ç›®éŒ„åç¨±ä½œç‚º ID
            name=config.experiment_name,
            created_at=datetime.fromisoformat(metrics["timestamp"]),
            config_path=str(config_file),
            train_runtime=metrics["train"]["runtime"],
            eval_accuracy=metrics["eval"]["accuracy"],
            log_path=str(exp_dir / "logs.txt"),
            # æ–°å¢æ•ˆèƒ½æŒ‡æ¨™
            tokens_per_sec=metrics["train"]["tokens_per_sec"],
            cpu_percent=metrics["system"]["cpu_percent"],
            memory_gb=metrics["system"]["memory_gb"],
            # æ–°å¢è¨“ç·´åƒæ•¸
            model_name=config.model.name,
            dataset_name=config.data.dataset_name,
            train_samples=config.data.train_samples,
            batch_size=config.training.per_device_train_batch_size,
            learning_rate=config.training.learning_rate,
            num_epochs=config.training.num_train_epochs,
        )
    )

    logger.info(f"âœ… å¯¦é©—çµæœå·²ä¿å­˜åˆ° {exp_dir} å’Œè³‡æ–™åº«")


def setup_experiment_dir(config):
    """è¨­ç½®å¯¦é©—ç›®éŒ„"""
    global logger

    # ç”Ÿæˆæ™‚é–“æˆ³
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

    # å»ºç«‹å¯¦é©—ç›®éŒ„
    exp_dir = Path("results") / f"{config.experiment_name}_{timestamp}"
    exp_dir.mkdir(exist_ok=True)

    # å»ºç«‹å­ç›®éŒ„
    artifacts_dir = exp_dir / "artifacts"
    artifacts_dir.mkdir(exist_ok=True)

    # è¨­ç½®æ—¥èªŒæ–‡ä»¶
    log_file = exp_dir / "logs.txt"

    # æ›´æ–°é…ç½®ä¸­çš„è·¯å¾‘
    config.training.output_dir = str(artifacts_dir)

    # è¨­ç½®å…¨å±€ logger
    logger = setup_system_logger(name=f"experiment_{timestamp}", log_file=str(log_file))

    return exp_dir


def parse_args():
    """è§£æå‘½ä»¤åˆ—åƒæ•¸"""
    parser = argparse.ArgumentParser(description="LoRA è¨“ç·´è…³æœ¬")
    parser.add_argument(
        "--config", type=str, default="config/default.yaml", help="é…ç½®æ–‡ä»¶è·¯å¾‘"
    )
    parser.add_argument("--experiment_name", type=str, help="å¯¦é©—åç¨±")
    parser.add_argument("--learning_rate", type=float, help="å­¸ç¿’ç‡")
    parser.add_argument("--epochs", type=int, help="è¨“ç·´è¼ªæ•¸")
    parser.add_argument("--train_samples", type=int, help="è¨“ç·´æ¨£æœ¬æ•¸")
    parser.add_argument("--device", type=str, help="è¨“ç·´è¨­å‚™")
    return parser.parse_args()


def main(config=None):
    """ä¸»å‡½æ•¸

    Args:
        config: é…ç½®å°è±¡ï¼Œå¦‚æœç‚º None å‰‡å¾å‘½ä»¤åˆ—åƒæ•¸è¼‰å…¥

    Returns:
        tuple: (train_result, eval_result) è¨“ç·´çµæœå’Œè©•ä¼°çµæœ
    """
    if config is None:
        # è§£æåƒæ•¸
        args = parse_args()

        # è¼‰å…¥é…ç½®
        config = load_config(args.config)

        # æ›´æ–°é…ç½®
        if args.experiment_name:
            config.experiment_name = args.experiment_name
        if args.learning_rate:
            config.training.learning_rate = args.learning_rate
        if args.epochs:
            config.training.num_train_epochs = args.epochs
        if args.train_samples:
            config.data.train_samples = args.train_samples
        if args.device:
            config.training.device = args.device

    # è¨­ç½®å¯¦é©—ç›®éŒ„å’Œæ—¥èªŒ
    exp_dir = setup_experiment_dir(config)
    logger.info(f"ğŸ“‚ å¯¦é©—ç›®éŒ„ï¼š{exp_dir}")

    # è¨­ç½®è¨­å‚™
    device = setup_device(config)

    # è¼‰å…¥æ¨¡å‹
    model, tokenizer = load_model_and_tokenizer(config, device)

    # è¼‰å…¥è³‡æ–™
    train_dataset, eval_dataset = load_and_process_data(config, tokenizer)

    # è¨­ç½® LoRA
    model = setup_lora(config, model, device)

    # è¨­ç½®è¨“ç·´
    trainer = setup_training(config, model, train_dataset, eval_dataset, exp_dir)

    # è¨“ç·´èˆ‡è©•ä¼°
    train_result, eval_result = train_and_evaluate(config, trainer)

    # ä¿å­˜å¯¦é©—çµæœ
    save_experiment_results(exp_dir, config, train_result, eval_result, trainer)

    return train_result, eval_result


if __name__ == "__main__":
    main()
