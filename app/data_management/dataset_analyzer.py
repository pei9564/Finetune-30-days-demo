"""
è³‡æ–™é›†åˆ†æå·¥å…·
æä¾›è³‡æ–™åˆ†å¸ƒåˆ†æã€æ‘˜è¦çµ±è¨ˆç­‰åŠŸèƒ½
"""

import json
import os
from collections import Counter
from datetime import datetime
from typing import Any, Dict, Optional

import numpy as np
from datasets import Dataset


def analyze_distribution(
    dataset: Dataset, label_column: str = "label"
) -> Dict[str, Any]:
    """
    åˆ†æè³‡æ–™é›†çš„é¡åˆ¥åˆ†å¸ƒ

    Args:
        dataset: Hugging Face Dataset ç‰©ä»¶
        label_column: æ¨™ç±¤æ¬„ä½åç¨±

    Returns:
        åŒ…å«çµ±è¨ˆè³‡è¨Šçš„å­—å…¸
    """
    # ç²å–æ¨™ç±¤
    labels = dataset[label_column]

    # çµ±è¨ˆå„é¡åˆ¥æ•¸é‡
    label_counts = Counter(labels)
    total_samples = len(labels)

    # è¨ˆç®—æ¯”ä¾‹
    label_percentages = {
        label: (count / total_samples) * 100 for label, count in label_counts.items()
    }

    # è¨ˆç®—çµ±è¨ˆæŒ‡æ¨™
    counts = list(label_counts.values())
    max_count = max(counts)
    min_count = min(counts)
    imbalance_ratio = max_count / min_count if min_count > 0 else float("inf")

    analysis = {
        "total_samples": total_samples,
        "num_classes": len(label_counts),
        "label_counts": dict(label_counts),
        "label_percentages": label_percentages,
        "imbalance_ratio": imbalance_ratio,
        "is_balanced": imbalance_ratio <= 3.0,  # èªç‚º 3:1 ä»¥å…§ç®—å¹³è¡¡
        "analysis_timestamp": datetime.now().isoformat(),
    }

    return analysis


def compare_datasets(
    datasets: Dict[str, Dataset],
    label_column: str = "label",
    save_dir: Optional[str] = None,
) -> Dict[str, Any]:
    """
    æ¯”è¼ƒå¤šå€‹è³‡æ–™é›†çš„åˆ†å¸ƒå·®ç•°

    Args:
        datasets: è³‡æ–™é›†å­—å…¸ {"name": dataset}
        label_column: æ¨™ç±¤æ¬„ä½åç¨±
        save_dir: å ±å‘Šä¿å­˜ç›®éŒ„

    Returns:
        æ¯”è¼ƒçµæœå­—å…¸
    """
    comparison = {"datasets": {}, "comparison_timestamp": datetime.now().isoformat()}

    # åˆ†ææ¯å€‹è³‡æ–™é›†
    for name, dataset in datasets.items():
        analysis = analyze_distribution(dataset, label_column)
        comparison["datasets"][name] = analysis

    # ä¿å­˜æ¯”è¼ƒå ±å‘Š
    if save_dir:
        os.makedirs(save_dir, exist_ok=True)
        report_path = os.path.join(save_dir, "datasets_comparison.json")
        save_analysis_report(comparison, report_path)

    return comparison


def save_analysis_report(
    analysis_or_comparison: Dict[str, Any], save_path: str
) -> None:
    """
    ä¿å­˜åˆ†æå ±å‘Šç‚º JSON æ–‡ä»¶

    Args:
        analysis_or_comparison: åˆ†æçµæœæˆ–æ¯”è¼ƒçµæœ
        save_path: ä¿å­˜è·¯å¾‘
    """
    os.makedirs(os.path.dirname(save_path), exist_ok=True)

    with open(save_path, "w", encoding="utf-8") as f:
        json.dump(analysis_or_comparison, f, ensure_ascii=False, indent=2)

    print(f"ğŸ“„ åˆ†æå ±å‘Šå·²ä¿å­˜è‡³: {save_path}")


def get_data_summary(dataset: Dataset) -> Dict[str, Any]:
    """
    ç²å–è³‡æ–™é›†åŸºæœ¬æ‘˜è¦è³‡è¨Š

    Args:
        dataset: Hugging Face Dataset ç‰©ä»¶

    Returns:
        æ‘˜è¦è³‡è¨Šå­—å…¸
    """
    summary = {
        "num_samples": len(dataset),
        "num_features": len(dataset.features),
        "feature_names": list(dataset.features.keys()),
        "feature_types": {
            name: str(feature) for name, feature in dataset.features.items()
        },
    }

    # æª¢æŸ¥æ–‡æœ¬é•·åº¦çµ±è¨ˆï¼ˆå¦‚æœæœ‰æ–‡æœ¬æ¬„ä½ï¼‰
    text_columns = []
    for col_name, feature in dataset.features.items():
        if "string" in str(feature).lower() or "text" in col_name.lower():
            text_columns.append(col_name)

    if text_columns:
        text_stats = {}
        for col in text_columns:
            texts = dataset[col]
            lengths = [len(text) if text else 0 for text in texts]
            text_stats[col] = {
                "avg_length": np.mean(lengths),
                "min_length": min(lengths),
                "max_length": max(lengths),
                "std_length": np.std(lengths),
            }
        summary["text_statistics"] = text_stats

    return summary


# ç¤ºä¾‹ä½¿ç”¨å‡½æ•¸
def analyze_glue_sst2_example():
    """ç¤ºä¾‹ï¼šåˆ†æ GLUE SST-2 è³‡æ–™é›†"""
    from datasets import load_dataset

    print("ğŸ“Š é–‹å§‹åˆ†æ SST-2 è³‡æ–™é›†...")

    # è¼‰å…¥è³‡æ–™é›†
    dataset = load_dataset("glue", "sst2")
    train_dataset = dataset["train"].select(range(1000))  # å– 1000 ç­†ç¯„ä¾‹

    # åŸºæœ¬æ‘˜è¦
    summary = get_data_summary(train_dataset)
    print("ğŸ“‹ è³‡æ–™é›†æ‘˜è¦:")
    print(f"   - æ¨£æœ¬æ•¸: {summary['num_samples']}")
    print(f"   - ç‰¹å¾µæ•¸: {summary['num_features']}")
    print(f"   - ç‰¹å¾µåç¨±: {summary['feature_names']}")

    # åˆ†æåˆ†å¸ƒ
    analysis = analyze_distribution(train_dataset)
    print("\nğŸ“Š é¡åˆ¥åˆ†å¸ƒåˆ†æ:")
    print(f"   - ç¸½æ¨£æœ¬æ•¸: {analysis['total_samples']}")
    print(f"   - é¡åˆ¥æ•¸: {analysis['num_classes']}")
    print(f"   - å„é¡åˆ¥æ•¸é‡: {analysis['label_counts']}")
    print(f"   - ä¸å¹³è¡¡æ¯”ä¾‹: {analysis['imbalance_ratio']:.2f}:1")
    print(f"   - æ˜¯å¦å¹³è¡¡: {'âœ…' if analysis['is_balanced'] else 'âŒ'}")

    # ä¿å­˜å ±å‘Š
    os.makedirs("data/metadata", exist_ok=True)
    save_analysis_report(analysis, "data/metadata/sst2_analysis.json")

    return analysis


if __name__ == "__main__":
    # åŸ·è¡Œç¤ºä¾‹åˆ†æ
    analyze_glue_sst2_example()
