# 實驗名稱
experiment_name: "default_experiment"  # 預設實驗名稱

# 模型配置
model:
  name: "distilbert-base-uncased"  # 使用 DistilBERT 模型
  num_labels: 2

# LoRA 配置
lora:
  r: 8  # LoRA 秩
  lora_alpha: 16  # LoRA alpha
  target_modules: ["q_lin", "v_lin"]  # 目標模組
  lora_dropout: 0.1
  bias: "none"
  task_type: "SEQ_CLS"

# 資料配置
data:
  dataset_name: "glue"
  dataset_config: "sst2"
  train_samples: 100
  eval_samples: 50
  max_length: 128
  validation_rules:
    min_text_length: 5
    max_text_length: 500
    allow_empty: false
    remove_html: true

# 訓練配置
training:
  output_dir: "./results"
  eval_strategy: "epoch"
  learning_rate: 5.0e-4  # 預設學習率
  per_device_train_batch_size: 2  # 預設批次大小
  num_train_epochs: 1  # 預設訓練輪數
  logging_steps: 10
  device: null  # 自動檢測

# 系統配置
system:
  log_file: "logs/training_progress.log"
  save_config: true