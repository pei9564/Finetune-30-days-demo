# Finetune-30-days â€” LoRA è¨“ç·´èˆ‡è³‡æ–™ç®¡ç†

æ­¤å°ˆæ¡ˆæä¾›ä¸€å€‹æœ€å°åŒ–çš„ **LoRA å¾®èª¿ç¯„ä¾‹**ï¼Œæ”¯æ´ M3 æ™¶ç‰‡ (MPS)ã€NVIDIA GPU (CUDA) èˆ‡ CPUã€‚
è¨­è¨ˆç›®æ¨™ï¼šå¿«é€Ÿå»ºç«‹ç’°å¢ƒã€é©—è­‰æµç¨‹ã€ä¿å­˜çµæœï¼Œä¸¦å…·å‚™ **è³‡æ–™ç‰ˆæœ¬ç®¡ç†èˆ‡é©—è­‰æ©Ÿåˆ¶**ã€‚

---

## ğŸ“‚ å°ˆæ¡ˆçµæ§‹

```
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ config.py                  # é…ç½®å®šç¾©èˆ‡ç®¡ç†
â”‚   â”œâ”€â”€ data_management/          # è³‡æ–™ç®¡ç†æ¨¡çµ„
â”‚   â”‚   â”œâ”€â”€ data_validator.py     # è³‡æ–™é©—è­‰èˆ‡æ¸…ç†
â”‚   â”‚   â”œâ”€â”€ dataset_analyzer.py   # æ¨™ç±¤åˆ†å¸ƒåˆ†æ
â”‚   â”‚   â””â”€â”€ version_manager.py    # è³‡æ–™ç‰ˆæœ¬æ§åˆ¶
â”‚   â”œâ”€â”€ logger_config.py          # æ—¥èªŒç³»çµ±
â”‚   â””â”€â”€ train_lora_v2.py         # LoRA è¨“ç·´ä¸»ç¨‹å¼
â”œâ”€â”€ config/
â”‚   â””â”€â”€ default.yaml              # é è¨­é…ç½®æ–‡ä»¶
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ configs/                  # å¯¦é©—é…ç½®è¨˜éŒ„
â”‚   â””â”€â”€ final_model/             # è¨“ç·´å®Œæˆçš„æ¨¡å‹
â”œâ”€â”€ logs/                         # è¨“ç·´èˆ‡é©—è­‰æ—¥èªŒ
â”œâ”€â”€ requirements.txt              # ä¾è³´ç®¡ç†
â”œâ”€â”€ Makefile                      # ç°¡åŒ–æŒ‡ä»¤
â””â”€â”€ README.md
```

---

## ğŸš€ å¿«é€Ÿé–‹å§‹

### åŸºæœ¬ä½¿ç”¨

```bash
make setup-conda   # å»ºç«‹ Conda ç’°å¢ƒï¼ˆè‡ªå‹•åµæ¸¬ GPU/MPS/CPUï¼‰
make run-local     # ä½¿ç”¨é è¨­é…ç½®é–‹å§‹è¨“ç·´
make logs-local    # æŸ¥çœ‹è¨“ç·´é€²åº¦
```

### è‡ªå®šç¾©è¨“ç·´

1. **ä¿®æ”¹é è¨­é…ç½®**ï¼š
   ç›´æ¥ç·¨è¼¯ `config/default.yaml`

2. **ä½¿ç”¨å‘½ä»¤åˆ—åƒæ•¸**ï¼š
   ```bash
   python app/train_lora_v2.py \
     --experiment_name "custom_test" \
     --learning_rate 0.001 \
     --epochs 3 \
     --train_samples 1000
   ```

### å¸¸ç”¨åƒæ•¸

```yaml
# åœ¨ config/default.yaml ä¸­å¯èª¿æ•´ï¼š

model:
  name: "distilbert-base-uncased"
  num_labels: 2

training:
  learning_rate: 5.0e-4
  num_train_epochs: 1
  per_device_train_batch_size: 2

lora:
  r: 8
  lora_alpha: 16
  target_modules: ["q_lin", "v_lin"]
  lora_dropout: 0.1
```

---

## ğŸ“Š å¯¦é©—è¨˜éŒ„

- **é…ç½®è¨˜éŒ„**ï¼š`results/configs/{å¯¦é©—åç¨±}_{æº–ç¢ºç‡}_{æ™‚é–“æˆ³}.yaml`
- **è¨“ç·´æ—¥èªŒ**ï¼š`logs/training_progress.log`
- **æ¨¡å‹ä¿å­˜**ï¼š`results/final_model/`

---

## ğŸ”§ è³‡æ–™ç®¡ç†å·¥å…·

ä»¥ä¸‹æŒ‡ä»¤ä½¿ç”¨é è¨­çš„ SST-2 ç¯„ä¾‹è³‡æ–™é›†ï¼Œåƒ…ä¾›é–‹ç™¼æ¸¬è©¦ç”¨é€”ã€‚
å¯¦éš›è¨“ç·´æ™‚ï¼Œé€™äº›åŠŸèƒ½å·²æ•´åˆåœ¨è¨“ç·´æµç¨‹ä¸­è‡ªå‹•åŸ·è¡Œã€‚

```bash
make data-analyze    # åˆ†ææ¨™ç±¤åˆ†å¸ƒ
make data-validate   # é©—è­‰è³‡æ–™å“è³ª
make data-versions   # ç®¡ç†è³‡æ–™ç‰ˆæœ¬
```

**è³‡æ–™é©—è­‰å ±å‘Šç¯„ä¾‹**ï¼š
```json
{
  "total_samples": 500,
  "label_counts": {"0": 245, "1": 255},
  "imbalance_ratio": 1.04,
  "is_balanced": true
}
```

---

## ğŸ’¡ æ³¨æ„äº‹é …

- é¦–æ¬¡ä½¿ç”¨è«‹åŸ·è¡Œ `make setup-conda` è¨­ç½®ç’°å¢ƒ
- ä½¿ç”¨ `make help` æŸ¥çœ‹å®Œæ•´çš„å‘½ä»¤èªªæ˜
- å¯¦é©—é…ç½®æœƒè‡ªå‹•ä¿å­˜ï¼Œæ–¹ä¾¿è¿½è¹¤å’Œé‡ç¾
- è³‡æ–™ç®¡ç†åŠŸèƒ½åœ¨è¨“ç·´æ™‚è‡ªå‹•åŸ·è¡Œï¼Œç¢ºä¿è³‡æ–™å“è³ª